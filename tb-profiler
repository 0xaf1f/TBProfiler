#! /usr/bin/python
from __future__ import division
import json
import sys
import subprocess
from collections import defaultdict
import argparse
import os
import re
import math
import gzip

################### Literals #####################
scriptDir = os.path.dirname(os.path.realpath(__file__))
tabix = scriptDir+"/bin/tabix"
htsbox = scriptDir+"/bin/htsbox"
snap = scriptDir+"/bin/snap-aligner"
bwa = scriptDir+"/bin/bwa"
lofreq = scriptDir+"/bin/lofreq"
samtools = scriptDir+"/bin/samtools"
bcftools = scriptDir+"/bin/bcftools"
get_reads = scriptDir+"/bin/get_covering_reads.py"
dr_bed_file = scriptDir+"/db/drdb.bed"
lin_bed_file = scriptDir+"/db/lineages.bed"
ref_dir = scriptDir+"/ref"
ref_file = ref_dir+"/MTB-h37rv_asm19595v2-eg18.fa"
ref_annotation = ref_dir+"/MTB-h37rv_asm19595v2-eg18.tab.ann.gz"
verbose = False
drdb = json.load(open(scriptDir+"/db/drdb.json"))

codons = {'CTT': 'Leu', 'ATG': 'Met', 'ACA': 'Thr', 'ACG': 'Thr', 'ATC': 'Ile', 'AAC': 'Asn', 'ATA': 'Ile', 'AGG': 'Arg', 'CCT': 'Pro', 'ACT': 'Thr', 'AGC': 'Ser', 'AAG': 'Lys', 'AGA': 'Arg', 'CAT': 'His', 'AAT': 'Asn', 'ATT': 'Ile', 'CTG': 'Leu', 'CTA': 'Leu', 'CTC': 'Leu', 'CAC': 'His', 'AAA': 'Lys', 'CCG': 'Pro', 'AGT': 'Ser', 'CCA': 'Pro', 'CAA': 'Gln', 'CCC': 'Pro', 'TAT': 'Tyr', 'GGT': 'Gly', 'TGT': 'Cys', 'CGA': 'Arg', 'CAG': 'Gln', 'TCT': 'Ser', 'GAT': 'Asp', 'CGG': 'Arg', 'TTT': 'Phe', 'TGC': 'Cys', 'GGG': 'Gly', 'TAG': 'Stop', 'GGA': 'Gly', 'TGG': 'Trp', 'GGC': 'Gly', 'TAC': 'Tyr', 'TTC': 'Phe', 'TCG': 'Ser', 'TTA': 'Leu', 'TTG': 'Leu', 'TCC': 'Ser', 'ACC': 'Thr', 'TAA': 'Stop', 'GCA': 'Ala', 'GTA': 'Val', 'GCC': 'Ala', 'GTC': 'Val', 'GCG': 'Ala', 'GTG': 'Val', 'GAG': 'Glu', 'GTT': 'Val', 'GCT': 'Ala', 'TGA': 'Stop', 'GAC': 'Asp', 'CGT': 'Arg', 'GAA': 'Glu', 'TCA': 'Ser', 'CGC': 'Arg'}
amino_acids = ['Cys', 'Ile', 'Ser', 'Val', 'Gly', 'Gln', 'Pro', 'Lys', 'Stop', 'Thr', 'Phe', 'Ala', 'Met', 'Asp', 'His', 'Leu', 'Arg', 'Trp', 'Glu', 'Asn', 'Tyr']
rc = {"A":"T","C":"G","G":"C","T":"A"}

################### Functions ####################

arch = open(scriptDir+"/arch.txt").readline().rstrip()
FNULL = open("/dev/null","w")

def check_files(r1,r2,bamfile):
	if verbose:
		print "Checking input files"

		programs = {}
		programs["linux"] = {"bwa":bwa,"htsbox":htsbox,"tabix":tabix,"snap":snap,"samtools":samtools,"bcftools":bcftools,"lofreq":lofreq}
		programs["mac"] = {"htsbox":htsbox,"bwa":bwa,"tabix":tabix,"samtools":samtools,"bcftools":bcftools,"lofreq":lofreq}
		programs["rpi"] = {"htsbox":htsbox,"bwa":bwa,"tabix":tabix,"samtools":samtools,"bcftools":bcftools,"lofreq":lofreq}

		for p in programs[arch]:
				if not os.path.isfile(programs[arch][p]):
						print "Can't find %s" % p
						quit()

	if bamfile:
		if r1 or r2:
			print "\nPlease provide only a bam file or read file(s) but not both\n"
			quit()
		file_exists(bamfile)
	else:
		if not r1:
			print "\nPlease provide at least one read file or bam file\n"
			quit()
		file_exists(r1)
		if r2:
			file_exists(r2)

def file_exists(filename):
	if not os.path.isfile(filename):
		print "Can't find %s" % filename
		quit()

def index_file(infile):
	subprocess.call("%s -f -b 2 -e 2 -s 1 %s" % (tabix,infile),shell=True)

def htsbox_calls(prefix,bedfile):
	bed_pos = set()
	for l in open(bedfile):
		arr = l.rstrip().split()
		for i in range(int(arr[1]),int(arr[2])+1):
			bed_pos.add((arr[0],str(i)))

	final_calls = defaultdict(lambda :defaultdict(list))
	rtnc = subprocess.call("%s view -L %s %s.bam -b > %s.temp.bam" % (samtools,bedfile,prefix,prefix),shell=True)
	if rtnc!=0:
		print "ERROR: htsbox command failed. Please run the following command to find out more:\n"
		print "%s view -L %s %s.bam -b > %s.temp.bam" % (samtools,bedfile,prefix,prefix)
		quit()
	for l in subprocess.Popen("%s pileup -Q 23 -q 30 %s.temp.bam" % (htsbox,prefix),shell=True,stdout=subprocess.PIPE).stdout:
		arr = l.rstrip().split()
		if (arr[0],arr[1]) not in bed_pos: continue
		calls = arr[3].split(",")
		cov = [int(x) for x in arr[4].split(":")[1].split(",")]
		tot = sum(cov)
		for i in range(len(calls)):
			final_calls[arr[0]][arr[1]].append((calls[i],cov[i]/tot,cov[i]))
	subprocess.call("rm %s.temp.bam"%prefix,shell=True)
	return final_calls

def stdev(arr):
	mean = sum(arr)/len(arr)
	return math.sqrt(sum([(x-mean)**2 for x in arr])/len(arr))

def assign_lin(prefix):
	if verbose:
		print "Checking lineage"
	calls = htsbox_calls(prefix,lin_bed_file)
#	calls = call_variants(prefix,lin_bed_file,"lineage")
	lin_meta_dict = {}
	lin_pos_dict = defaultdict(dict)
	for l in open(lin_bed_file):
		arr = l.rstrip().split("\t")
		lin_meta_dict[arr[3]] = arr[6:]
		lin_pos_dict[arr[0]][arr[1]] = {"ref":arr[4],"alt":arr[5],"lin":arr[3]}

	lin_support = defaultdict(list)
	sample_lin = set()
	for chrom in lin_pos_dict:
		for pos in lin_pos_dict[chrom]:
			if pos not in calls[chrom]: continue
			if lin_pos_dict[chrom][pos]["alt"] in [x[0] for x in calls[chrom][pos]]:
				lin_support[lin_pos_dict[chrom][pos]["lin"]].append((sum([x[2] for x in calls[chrom][pos] if x[0]==lin_pos_dict[chrom][pos]["alt"]]),sum([x[2] for x in calls[chrom][pos] if x[0]!=lin_pos_dict[chrom][pos]["alt"]])))
			else:
				lin_support[lin_pos_dict[chrom][pos]["lin"]].append((0,sum([x[2] for x in calls[chrom][pos] if x[0]!=lin_pos_dict[chrom][pos]["alt"]])))
	lin_frac = defaultdict(float)
	for l in lin_support:
		if stdev([x[0]/(x[0]+x[1]) for x in lin_support[l]])>0.1: continue
		lin_pos_reads = sum([x[0] for x in lin_support[l]])
		lin_neg_reads = sum([x[1] for x in lin_support[l]])
		lf = lin_pos_reads/(lin_pos_reads+lin_neg_reads)
		if lf<0.05:continue
		lin_frac[l] = lf
		sample_lin.add(l)
	lin_str = ""
	lin_list = []
	for l in sorted(list(sample_lin)):
		lin_list.append({"lin":l,"frac":lin_frac[l],"family":lin_meta_dict[l][0],"spoligotype":lin_meta_dict[l][1],"rd":lin_meta_dict[l][2]})
		lin_str+= "%s\t%s\t%s\t%s\t%s\n" % (l,lin_frac[l],lin_meta_dict[l][0],lin_meta_dict[l][1],lin_meta_dict[l][2])
	if verbose:
		print lin_str
	return lin_list





def load_ann(bed_name,qtype = "T"):
	if verbose:
		print "Loading annotation"
	ann_dict = defaultdict(dict)
	annCMD = "%s %s -%s %s" % (tabix,ref_annotation,qtype,bed_name)
	annPIPE = subprocess.Popen(annCMD,shell=True,stdout=subprocess.PIPE)
	for l in annPIPE.stdout:
		arr = l.rstrip().split()
		ann_dict[arr[0]][arr[1]] = {"change_pos":arr[7],"ref_nt":arr[2],"ref_codon":arr[6],"ref_aa":arr[11],"chr":arr[0],"pos":arr[1],"rv":arr[15],"gene":arr[16],"gene_syn":arr[17],"ncr":arr[18],"start":arr[19],"end":arr[20],"strand":arr[21],"codon_num":arr[24],"gene_nt":arr[25],"operon":arr[26]}
	return ann_dict

def do_mapping(r1,r2,threads,prefix,mapper):
	if verbose:	print "Performing mapping"
	if arch=="linux":
		if mapper=="snap":
			if r2:
				cmd_mapping = "set -euf pipefail; %s paired %s -compressedFastq %s %s -t %s -o -bam - | %s sort -o %s.bam -@ %s - && %s index %s.bam" % (snap,ref_dir,r1,r2,threads,samtools,prefix,threads,samtools,prefix)
			else:
				cmd_mapping = "set -euf pipefail; %s single %s -compressedFastq %s -t %s -o -bam - | %s sort -o %s.bam -@ %s - && %s index %s.bam" % (snap,ref_dir,r1,threads,samtools,prefix,threads,samtools,prefix)
		elif mapper=="bwa":
			if r2:
				cmd_mapping = "set -euf pipefail; %s mem -t %s %s %s %s | %s view -@ %s -b - | %s sort -@ %s -o %s.bam - && %s index %s.bam" % (bwa,threads,ref_file,r1,r2,samtools,threads,samtools,threads,prefix,samtools,prefix)
			else:
				cmd_mapping = "set -euf pipefail; %s mem -t %s %s %s | %s view -@ %s -b - | %s sort -@ %s -o %s.bam - && %s index %s.bam" % (bwa,threads,ref_file,r1,samtools,threads,samtools,threads,prefix,samtools,prefix)
	elif arch=="mac":
		if r2:
			cmd_mapping = "set -euf pipefail; %s mem -t %s %s %s %s | %s view -@ %s -b - | %s sort -@ %s -o %s.bam - && %s index %s.bam" % (bwa,threads,ref_file,r1,r2,samtools,threads,samtools,threads,prefix,samtools,prefix)
		else:
			cmd_mapping = "set -euf pipefail; %s mem -t %s %s %s | %s view -@ %s -b - | %s sort -@ %s -o %s.bam - && %s index %s.bam" % (bwa,threads,ref_file,r1,samtools,threads,samtools,threads,prefix,samtools,prefix)
	elif arch=="rpi":
		if r2:
			cmd_mapping = "set -euf pipefail; zcat %s %s | gzip -c > %s.merged.fq.gz && %s aln -t %s %s %s.merged.fq.gz > %s_1.sai && %s samse %s %s_1.sai %s.merged.fq.gz | %s view -@ %s -b - > %s.unsort.bam && %s sort -m 200M -o %s.bam %s.unsort.bam && rm %s_1.sai %s_2.sai %s.unsort.bam && %s index %s.bam" % (r1,r2,prefix,bwa,threads,ref_file,prefix,prefix,bwa,ref_file,prefix,prefix,samtools,threads,prefix,samtools,prefix,prefix,prefix,prefix,prefix,samtools,prefix)
		else:
			cmd_mapping = "set -euf pipefail; %s aln -t %s %s %s > %s_1.sai && %s samse %s %s_1.sai %s | %s view -@ %s -b - > %s.unsort.bam | %s sort -m 600M -o %s.bam %s.unsort.bam && rm %s_1.sai %s_2.sai %s.unsort.bam && %s index %s.bam" % (bwa,threads,ref_file,r2,prefix,bwa,ref_file,prefix,r1,samtools,threads,prefix,samtools,prefix,prefix,prefix,prefix,prefix,samtools,prefix)
	if verbose: print cmd_mapping
	rntc = subprocess.call(cmd_mapping,shell=True,stderr=FNULL,stdout=FNULL)
	if rntc == 1:
		print "ERROR: Mapping command failed. Please run the following to find out more:\n"
		print cmd_mapping
		quit()

def call_variants(prefix,bed_file,file_prefix):
	if verbose:	print "Calling Variants"
	bamfile = prefix+".bam"
	file_exists(bamfile)
	vcf_file = "%s.%s.vcf" % (prefix,file_prefix)
	lofreq_cmd = "set -euf pipefail; %s view -bL %s %s | %s indelqual -u 30 - |%s call -f %s --call-indels --no-default-filter - | %s norm -f %s - > %s" % (samtools,bed_file,bamfile,lofreq,lofreq,ref_file,bcftools,ref_file,vcf_file)
	if verbose: print lofreq_cmd
	rtnc = subprocess.call(lofreq_cmd,shell=True,stdout=FNULL,stderr=FNULL)
	if rtnc!=0:
		print "ERROR: Variant calling command failed. Please run the following command to find out more:\n"
		print lofreq_cmd
		quit()

	bed_pos = set()
	for l in open(bed_file):
		arr = l.rstrip().split()
		for i in range(int(arr[1]),int(arr[2])+1):
			bed_pos.add((arr[0],str(i)))
	rare_var = []
	final_calls = defaultdict(lambda:defaultdict(dict))
	for l in open(vcf_file):
		if l[0]=="#": continue
		#Chromosome	4326451	.	TGCG	TGCGCG	225	.	INDEL;IDV=126;IMF=0.9;DP=140;VDB=0.00626444;SGB=-0.693147;MQSB=1;MQ0F=0;AC=1;AN=1;DP4=0,0,61,66;MQ=60	GT:PL	1:255,0
		arr = l.rstrip().split()
		if (arr[0],arr[1]) not in bed_pos:
			continue

		DP4 = [int(x) for x in re.search("DP4=([\d,]+)",l).group(1).split(",")]
		if sum(DP4)==0:continue
		DP4r = (DP4[2]+DP4[3])/(DP4[0]+DP4[1]+DP4[2]+DP4[3])
		if "," in arr[4]:
			print "Tri allelic site"
			quit()
		if (DP4r>0.1 and DP4r<0.9):
			if len(arr[3])>1 or len(arr[4])>1:
				final_calls[arr[0]][arr[1]] = [(arr[3],1-DP4r,DP4[0]+DP4[1]),(arr[4],DP4r,DP4[2]+DP4[3])]

			final_calls[arr[0]][arr[1]] = [(arr[3],1-DP4r,DP4[0]+DP4[1]),(arr[4],DP4r,DP4[2]+DP4[3])]
#			rare_var.append((arr[0],int(arr[1])))
		else:
			if DP4r<=0.1: continue
			else:
				if len(arr[3])>1 or len(arr[4])>1:
					final_calls[arr[0]][arr[1]] = [(recode_indel(arr[3],arr[4]),1.0,DP4[2]+DP4[3])]
				else:
					final_calls[arr[0]][arr[1]] = [(arr[4],1.0,DP4[2]+DP4[3])]

	return final_calls


def recode_indel(ref,alt):
	if len(ref)<len(alt):
		ldiff = len(alt)-len(ref)
		return "%s+%s%s" % (ref[:1],ldiff,ref[1:1+ldiff])
	else:
		ldiff = len(ref)-len(alt)
		return "%s-%s%s" % (ref[:1],ldiff,ref[1:1+ldiff])
	return indel

def small_dr_var(prefix,gene_del_set):
	# File name definitions
	temp_bed = prefix+".temp.bed"

	# Open dr gene bed file
	dr_pos = defaultdict(list)
	for l in open(dr_bed_file):
		arr = l.rstrip().split()
		for i in range(int(arr[1]),int(arr[2])+1):
			dr_pos[arr[0]].append(str(i))

	temp_variants = call_variants(prefix,dr_bed_file,"dr")
	htsbox_variants = htsbox_calls(prefix,dr_bed_file) #'2726321': [('C', 1.0, 61)]

#	temp_variants = {'Chromosome': {'4240670': [('C', 0.34075471698113206), ('G', 0.03773584905660377), ('T', 0.6515094339622641)], '4240671': [('C', 0.32075471698113206), ('G', 0.03773584905660377), ('T', 0.6415094339622641)]}}
	variants = defaultdict(dict)
	var_loci = []
	OUT = open(temp_bed,"w")
	for chrom in sorted(temp_variants):
		for pos in [str(y) for y in sorted([int(x) for x in temp_variants[chrom]])]:
			if pos not in dr_pos[chrom]: continue
			variants[chrom][pos] = temp_variants[chrom][pos]
			var_loci.append([chrom,pos])
			OUT.write("%s\t%s\t%s\n" % (chrom,int(pos)-1,int(pos)))
	OUT.close()
	ann = load_ann(temp_bed,"T")
	variant_bin = defaultdict(lambda:defaultdict(list))
	gene_type = {}
	for chrom,pos in var_loci:
		if ann[chrom][pos]["rv"] not in [x["locus_tag"] for x in drdb]:
			continue
		if ann[chrom][pos]["rv"] in gene_del_set:
			continue
		gene_type[ann[chrom][pos]["rv"]] = ann[chrom][pos]["ncr"]
		if ann[chrom][pos]["ncr"]=="CDS":
				variant_bin[ann[chrom][pos]["rv"]][ann[chrom][pos]["codon_num"]].append((chrom,pos))
		else:
				variant_bin[ann[chrom][pos]["rv"]][ann[chrom][pos]["gene_nt"]].append((chrom,pos))
	dr_variants = []
	other_variants = []
	#alt_bins = [[['C'], 0.16666666666666666], [['T'], 0.8333333333333334]]

	for rv in variant_bin:
		for change_pos in variant_bin[rv]:
			chrom = variant_bin[rv][change_pos][0][0]
			nt_positions = [x[1] for x in variant_bin[rv][change_pos]]
			genome_pos = ",".join(nt_positions)
			pos = nt_positions[0]
			positions = variant_bin[rv][change_pos]
			if set([len(x) for x in [variants[chrom][p] for p in nt_positions]])==set([1]):
				alt_bins = [([item[0] for sublist in [variants[chrom][p] for p in nt_positions] for item in sublist],1.0)]
			elif len([variants[chrom][p] for p in nt_positions])==1:
				alt_bins = [[[item[0]],item[1]] for sublist in [htsbox_variants[chrom][p] for p in nt_positions] for item in sublist]
			else:
				alt_bins = []
				tplp = {}
				temp_refs = {}
				for l in subprocess.Popen("%s view %s.bam Chromosome:%s-%s -h | python %s %s | %s view -b | %s mpileup -Q0 -f %s - " % (samtools,prefix,pos,pos,get_reads,",".join(nt_positions),samtools,samtools,ref_file),shell=True,stderr=FNULL,stdout=subprocess.PIPE).stdout:
					arr = l.rstrip().split()
					if arr[1] in nt_positions:
						tplp[arr[1]] = arr[4].upper()
						temp_refs[arr[1]] = arr[2]
				counts = defaultdict(int)
				pileup = {}
				for p in nt_positions:
					pileup[p] = []
					i=0
					while(i<len(tplp[p])):
						if i+1==len(tplp[p]):
							pileup[p].append(temp_refs[p] if tplp[p][i]=="." or tplp[p][i]=="," else tplp[p][i])
							i+=1
						elif tplp[p][i+1]!="-" and tplp[p][i+1]!="+":
							pileup[p].append(temp_refs[p] if tplp[p][i]=="." or tplp[p][i]=="," else tplp[p][i])
							i+=1
						elif tplp[p][i+1]=="-" or tplp[p][i+1]=="+":
							indel_len = int(re.match("(\d+)",tplp[p][i+2:]).group(1))
							indel_nchar = len(str(indel_len))
							extra_seq = tplp[p][i+2+indel_nchar:i+2+indel_nchar+indel_len]
							sbase = temp_refs[p] if tplp[p][i]=="." or tplp[p][i]=="," else tplp[p][i]

							pileup[p].append("%s%s%s%s" % (sbase,tplp[p][i+1],indel_len,extra_seq))
							i+=+2+indel_nchar+indel_len
						else:
							print "ERROR 0: Please contact flag up an issue at the TBProfiler github"
							quit()



				for i in range(len(pileup[nt_positions[0]])):
					k = tuple([pileup[x][i] for x in nt_positions])
					counts[k]+=1
				for k in counts:
					freq = counts[k]/len(pileup[nt_positions[0]])
					alt_bins.append([list(k),freq])

			alt_bins = [x for x in alt_bins if "*" not in x[0]]
			alt_bins = [x for x in alt_bins if x[1]>0.05] #filtering out haplotypes which are less than 0.05 in freq

			for alts,alts_freq in alt_bins:

				res = [dr for dr in drdb if dr["genome_pos"]==nt_positions and dr["alt_nt"]==alts]

				change_str = ""
				var_type = ""
				if "+" in "".join(alts) or "-" in "".join(alts):
					if len(alts)!=1:
						print "Don't know what to do! ERROR!!"
						quit()

					change_str = "%s%s%s" % (ann[chrom][pos]["ref_nt"],ann[chrom][pos]["gene_nt"],alts[0])
					var_type = "INDEL"
				elif ann[chrom][pos]["change_pos"]!=".":
					ref_codon = ann[positions[0][0]][positions[0][1]]["ref_codon"]
					temp_vars = []
					for i,(chrom,pos) in enumerate(positions):
						temp_vars.append((chrom,pos,ann[chrom][pos]["ref_nt"],alts[i]))

					alt_var = list(ref_codon)
					for arr in temp_vars:
						chom,pos,ref,var = arr[0],arr[1],arr[2],arr[3]
						temp_c_pos = int(ann[chrom][pos]["change_pos"])-1
						alt_var[temp_c_pos] = rc[var] if ann[chrom][pos]["strand"] == "-" else var
					if alt_var==list(ref_codon): continue
					alt_var = "".join(alt_var)
					change_str = "%s%s%s" % (codons[ref_codon],ann[chrom][pos]["codon_num"],codons[alt_var])
					var_type = "SNP"
				else:
					if len(alts)!=1:
						print "ERROR!!!"
						quit()
					var = alts[0]
					if var==ann[positions[0][0]][positions[0][1]]["ref_nt"]: continue
					change_str = "%s%s%s" % (ann[chrom][pos]["ref_nt"],ann[chrom][pos]["gene_nt"],var)
					var_type = "SNP"
				if len(res)==1:
					res = res[0]
					for d in res["drug"]:
						dr_variants.append({"drug":d,"locus_tag":ann[chrom][pos]["rv"],"gene":ann[chrom][pos]["gene"],"genome_pos":genome_pos,"chr":chrom,"change":change_str,"type":var_type,"freq":str(round(alts_freq,2))})
				elif len(res)==0:
					other_variants.append({"locus_tag":ann[chrom][pos]["rv"],"gene":ann[chrom][pos]["gene"],"genome_pos":genome_pos,"chr":chrom,"change":change_str,"type":var_type,"freq":str(round(alts_freq,2))})
				else:
					print "ERRROORRR!!!"
					quit()
	return dr_variants,other_variants


def large_dels(prefix):

	lt_bed = defaultdict(dict)
	lt_cov = defaultdict(lambda : defaultdict(int))
	lt_drugs = {}
	lt2gene = {}
	for l in open(dr_bed_file):
		chrom,start,end,lt,gene,drugs = l.rstrip().split()
		lt_drugs[lt] = drugs
		for pos in range(int(start),int(end)+1):
			lt_cov[lt][str(pos)] = 0
			lt_bed[chrom][str(pos)] = lt
			lt2gene[lt] = gene
	bamfile = prefix+".bam"

	for l in subprocess.Popen("%s depth -b %s %s" % (samtools,dr_bed_file,bamfile),shell=True,stdout=subprocess.PIPE).stdout:
		chrom,pos,depth =  l.rstrip().split()
		lt_cov[lt_bed[chrom][pos]][pos] = depth
	results = []
	for lt in lt_cov:
		arr_cov = lt_cov[lt].values()
		int_good_cov = len(filter(lambda x: x>10,arr_cov))
		float_gene_present = int_good_cov/len(arr_cov)

		if float_gene_present<0.95:
			if lt=="Rv0667":
				print "Missing coverage on essential gene rpoB. Stopping pipeline. Check for contamination"
				return []
				quit()
			results.append({"drug":lt_drugs[lt],"gene":lt2gene[lt],"locus_tag":lt,"len":len(arr_cov),"good_cov":int_good_cov,"float_gene_present":float_gene_present})

	return results

def cleanup(prefix,clean,stor_dir,bamfile):
	if verbose:
		print "Cleaning up"

	if clean:
		subprocess.call("rm %s.bam* %s.dr.vcf %s.lineage.vcf %s.temp.bed" % (prefix,prefix,prefix),shell=True)
	else:
		subprocess.call("rm %s.temp.bed" % (prefix),shell=True)
		if bamfile:
				subprocess.call("rm %s.bam*" % (prefix),shell=True)
		else:
			subprocess.call("mv %s.bam* %s/bam" % (prefix,stor_dir),shell=True)
		subprocess.call("mv %s.*.vcf %s/vcf" % (prefix,stor_dir),shell=True)
	subprocess.call("mv %s.results.txt %s.results.json %s/results" % (prefix,prefix,stor_dir),shell=True)

def init_storage(clean,stor_dir):
	if clean:
		tdir = stor_dir+"/results"
		if not os.path.isdir(tdir):
			subprocess.call("mkdir %s" % tdir,shell=True)
	else:
		for x in ["bam","vcf","results"]:
			tdir = stor_dir+"/"+x
			if not os.path.isdir(tdir):
				subprocess.call("mkdir %s" % tdir,shell=True)

def write_results_2(prefix,small_var_dr,small_var_other,dels,lin):
	if verbose:
		print "Writing outputs"
	drugs = load_drgus()
	o = open(prefix+".results.txt","w")
	o.write("#### %s results ####\n\n" % prefix)
	o.write("#### Drug resistance associated small variants ####\n")
	for d in drugs:
		dr_vars = [x for x in small_var_dr if x["drug"]==d]
		res = "R" if len(dr_vars)>0 else ""
		muts = ["%(gene)s (%(change)s, %(freq)s)" % x for x in dr_vars]
		o.write("%s\t%s\t%s\n" % (d,res,", ".join(muts)))
	dr_drugs = [x["drug"] for x in small_var_dr]

	MDR = "R" if ("ISONIAZID" in dr_drugs and "RIFAMPICIN" in dr_drugs) else ""
	XDR = "R" if MDR=="R" and ( "AMIKACIN" in dr_drugs or "KANAMYCIN" in dr_drugs or "CAPREOMYCIN" in dr_drugs ) and ( "FLUOROQUINOLONES" in dr_drugs) else ""
	o.write("MDR\t%s\n" % MDR)
	o.write("XDR\t%s\n" % XDR)

	o.write("\n\n#### Big Deletions in candidate genes ####\n")
	for l in dels:
		o.write("\t".join([str(l[x]) for x in ["drug","gene","len","good_cov",'float_gene_present']])+"\n")
	o.write("\n\n#### Lineage ####\n")
	o.write("\n".join(["%s\t%s\t%s\t%s\t%s" % (x["lin"],x["frac"],x["family"],x["spoligotype"],x["rd"]) for x in lin]))

	o.write("\n\n#### Other small variants in candidate genes ####\n")
	for l in small_var_other:
		o.write("\t".join([l[x] for x in ["chr","genome_pos","gene","locus_tag","change","type"]])+"\n")
	o.close()

	json_dict = {"small_variants_other":small_var_other,"small_variants_dr":small_var_dr,"del":dels,"lineage":lin,"id":prefix}

	json.dump(json_dict,open(prefix+".results.json","w"))

def write_results_1(prefix,small_var_dr,small_var_other,dels,lin):
	if verbose:
		print "Writing outputs"
	drugs = load_drgus()
	o = open(prefix+".results.txt","w")
	o.write("#### %s results ####\n\n" % prefix)
	o.write("#### Drug resistance associated small variants ####\n")
	for l in small_var_dr:
		o.write("\t".join([l[x] for x in ["drug","chr","genome_pos","gene","locus_tag","change","type","freq"]])+"\n")
	o.write("\n\n#### Big Deletions in candidate genes ####\n")
	for l in dels:
		o.write("\t".join([str(l[x]) for x in ["drug","gene","len","good_cov",'float_gene_present']])+"\n")
	o.write("\n\n#### Lineage ####\n")
	o.write("\n".join(["%s\t%s\t%s\t%s\t%s" % (x["lin"],x["frac"],x["family"],x["spoligotype"],x["rd"]) for x in lin]))
	o.write("\n\n#### Other small variants in candidate genes ####\n")
	for l in small_var_other:
		o.write("\t".join([l[x] for x in ["chr","genome_pos","gene","locus_tag","change","type","freq"]])+"\n")
	o.close()

	json_dict = {"small_variants_other":small_var_other,"small_variants_dr":small_var_dr,"del":dels,"lineage":lin,"id":prefix}

	json.dump(json_dict,open(prefix+".results.json","w"))

def load_drgus():
	drugs = set()
	for l in open(dr_bed_file):
		arr = l.rstrip().split()
		for d in arr[5].split(";"):
			drugs.add(d)
	return sorted(list(drugs))


def results2tab(samples,outfile,stor_dir,itol):
	drugs = load_drgus()
	results = defaultdict(dict)
	linresults = defaultdict(dict)
	for s in samples:
		for d in drugs:
			results[s][d] = "-"
	for s in samples:
		temp = json.load(open("%s/results/%s.results.json" % (stor_dir,s)))
		for x in temp["small_variants_dr"]:
			for d in x["drug"].split(";"):
				results[s][d] = "R"
		for x in temp["del"]:
			for d in x["drug"].split(";"):
				results[s][d] = "R"
		linresults[s]["main"] = sorted([x["lin"] for x in temp["lineage"]])[0] if len(temp["lineage"])>0 else "-"
		linresults[s]["sublin"] = sorted([x["lin"] for x in temp["lineage"]])[-1] if len(temp["lineage"])>0 else "-"
		dr_drugs = [x["drug"] for x in temp["small_variants_dr"]]

		MDR = "R" if ("ISONIAZID" in dr_drugs and "RIFAMPICIN" in dr_drugs) else "-"
		XDR = "R" if MDR=="R" and ( "AMIKACIN" in dr_drugs or "KANAMYCIN" in dr_drugs or "CAPREOMYCIN" in dr_drugs ) and ( "FLUOROQUINOLONES" in dr_drugs) else "-"
		drtype = "Sensitive"
		if XDR=="R":
			drtype="XDR"
		elif MDR=="R":
			drtype="MDR"
		elif len(dr_drugs)>0:
			drtype="Drug-resistant"
		results[s]["XDR"] = XDR
		results[s]["MDR"] = MDR
		results[s]["drtype"] = drtype

	o = open(outfile,"w")
	o.write("sample\tmain_lineage\tsub_lineage\tDR_type\tMDR\tXDR\t%s" % "\t".join(drugs)+"\n")
	for s in samples:
		o.write("%s\t%s\t%s\t%s\t%s\t%s\t%s\n" %(s,linresults[s]["main"],linresults[s]["sublin"],results[s]["drtype"],results[s]["MDR"],results[s]["XDR"],"\t".join([results[s][x] for x in drugs])))
	o.close()

	lineage_cols = {"lineage1":"#FF0000","lineage2":"#FFBF00","lineage3":"#80FF00","lineage4":"#00FF40","lineage5":"#00FFFF","lineage6":"#0040FF","lineage7":"#8000FF","lineageBOV":"#FF00BF"}
	o = open(outfile+".lineage.itol.txt","w")
	o.write("""DATASET_COLORSTRIP
SEPARATOR TAB
DATASET_LABEL	Lineage
COLOR	#ff0000

LEGEND_TITLE	Lineage
LEGEND_SHAPES	1	1	1	1	1	1	1	1	1
LEGEND_COLORS	#FF0000	#FFBF00	#80FF00	#00FF40	#00FFFF	#0040FF	#8000FF	#FF00BF	#000000
LEGEND_LABELS	Lineage1	Lineage2	Lineage3	Lineage4	Lineage5	Lineage6	Lineage7	Bovis	Other

DATA
""")
	for s in samples:
		o.write("%s\t%s\n" % (s,lineage_cols.get(linresults[s]["main"],"#000000")))
	o.close()

	o = open(outfile+".dr.itol.txt","w")
	dr_cols = {"Sensitive":"#80FF00","Drug-resistant":"#00FFFF","MDR":"#8000FF","XDR":"#FF0000"}
	o.write("""DATASET_COLORSTRIP
SEPARATOR TAB
DATASET_LABEL	Lineage
COLOR	#ff0000

LEGEND_TITLE	Drug resistance
LEGEND_SHAPES	1	1	1	1
LEGEND_COLORS	#80FF00	#00FFFF	#8000FF	#FF0000
LEGEND_LABELS	Sensitive	Drug-resisant	MDR	XDR

DATA
""")
	for s in samples:
		o.write("%s\t%s\n" % (s,dr_cols.get(results[s]["drtype"],"#000000")))
	o.close()



def verify_fq(filename):
	FQ = open(filename) if filename[-3:]!=".gz" else gzip.open(filename)
	l1 = FQ.readline()
	if l1[0]!="@":
		print "First character is not \"@\"\nPlease make sure this is fastq format\nExiting..."
		quit()


################ Main functions ##################

def main_run_pipeline(args):
	if args.verbose:
		global verbose
		verbose=True
	if args.db!="default":
		global drdb
		global dr_bed_file
		drdb = json.load(open(scriptDir+"/db/"+args.db+".json"))
		dr_bed_file = scriptDir+"/db/"+args.db+".bed"

	check_files(args.read1,args.read2,args.bam)
	init_storage(args.clean,args.dir)
	if args.read1:
		verify_fq(args.read1)
		do_mapping(args.read1,args.read2,args.threads,args.prefix,args.mapping)
	else:
		if not os.path.isfile("%s.bam"%args.prefix):
			if verbose:
				print "Symbolic linking bam and indexing"
			rtnc = subprocess.call("ln -s %s %s.bam && %s index %s.bam" % (args.bam,args.prefix,samtools,args.prefix),shell=True)
			if rtnc!=0:
				print "ERROR: Linking command failed. Please run the following command to find out more:\n"
				print "ln -s %s %s.bam && %s index %s.bam" % (args.bam,args.prefix,samtools,args.prefix)
				quit()
	lin = assign_lin(args.prefix)
	big_dels = large_dels(args.prefix)
	gene_del_set =  set([x["locus_tag"] for x in big_dels])
	small_dr_variants,small_other_variants = small_dr_var(args.prefix,gene_del_set)
	if args.format=="classic":
		write_results_2(args.prefix,small_dr_variants,small_other_variants,big_dels,lin)
	elif args.format=="new":
		write_results_1(args.prefix,small_dr_variants,small_other_variants,big_dels,lin)
	cleanup(args.prefix,args.clean,args.dir,args.bam)

def main_collate(args):

	samples = [x.rstrip() for x in open(args.samples_file).readlines()]
	results2tab(samples,args.out_file,args.dir,args.itol)

def main_version(args):
	print "\nTBProfiler version 0.2.1\n\nContact: Jody Phelan (jody.phelan@lshtm.ac.uk)\n"
####################### Argument Parser ###########################

parser = argparse.ArgumentParser(description='TBProfiler pipeline',formatter_class=argparse.ArgumentDefaultsHelpFormatter)
subparsers = parser.add_subparsers(help="Task to perform")

parser_sub = subparsers.add_parser('full', help='Run whole pipeline', formatter_class=argparse.ArgumentDefaultsHelpFormatter)
parser_sub.add_argument('--read1','-1',help='First read file')
parser_sub.add_argument('--read2','-2',help='Second read file')
parser_sub.add_argument('--bam','-a',help='Second read file')
parser_sub.add_argument('--prefix','-p',default="tbprofiler",help='Sample prefix')
parser_sub.add_argument('--threads','-t',default="1",help='Threads')
parser_sub.add_argument('--clean',help="Remove temporary files",action="store_true")
parser_sub.add_argument('--dir','-d',default=".",help='Storage directory')
parser_sub.add_argument('--db','-b',default="default",help='Full path to mutation database json file to use (default: TBProfiler panel)')
parser_sub.add_argument('--format','-f',default="classic",help='Output format [classic,new]')
if arch=="mac":
	parser_sub.add_argument("--mapping","-m",type=str,default="bwa",choices=["bwa"],help="Change the default mapping tool (Linux:[snap|bwa], Mac:[bwa]). Only bwa is available for Mac")
elif arch=="linux":
	parser_sub.add_argument("--mapping","-m",type=str,default="snap",choices=["bwa","snap"],help="Change the default mapping tool (Linux:[snap|bwa], Mac:[bwa]). Only bwa is available for Mac")
parser_sub.add_argument('--verbose',help="Remove temporary files",action="store_true")
parser_sub.set_defaults(func=main_run_pipeline)


parser_sub = subparsers.add_parser('collate', help='Collate results form multiple samples together', formatter_class=argparse.ArgumentDefaultsHelpFormatter)
parser_sub.add_argument('samples_file',help='File with samples (one per line)')
parser_sub.add_argument('out_file',help='Output file name')
parser_sub.add_argument('--dir','-d',default=".",help='Storage directory')
parser_sub.add_argument('--itol',help='Generate ITOL file',action="store_true")
parser_sub.set_defaults(func=main_collate)


parser_sub = subparsers.add_parser('version', help='Output program version and exit', formatter_class=argparse.ArgumentDefaultsHelpFormatter)
parser_sub.set_defaults(func=main_version)



args = parser.parse_args()
args.func(args)
